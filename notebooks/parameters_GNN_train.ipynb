{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS Vivobook\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"D:/gnn-cloud-manufacturing/\")\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from tqdm.auto import trange\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import trange\n",
    "from cloudmanufacturing.data import read_fatahi_dataset\n",
    "from cloudmanufacturing.validation import objvalue, construct_delta, Dataset, validate\n",
    "from cloudmanufacturing.graph import os_type\n",
    "from cloudmanufacturing.graphconv import GNN\n",
    "import dgl\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "import torch\n",
    "from torch.optim import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:24<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "with open('../data/train_dataset/train_data_sheet_names.pickle' , 'rb') as s:\n",
    "    sheet_names = pickle.load(s)\n",
    "dataset = read_fatahi_dataset('../data/train_dataset/train_data_OPTIMAL.xlsx', sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/train_dataset/train_data_solve.pickle' , 'rb') as f:\n",
    "    # Загружаем dgl графы в список\n",
    "    DGList = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': '3,24,19-11',\n",
       " 'n_tasks': 3,\n",
       " 'n_operations': 24,\n",
       " 'n_cities': 19,\n",
       " 'n_services': 1,\n",
       " 'operation': array([[0., 1., 1.],\n",
       "        [0., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 0.],\n",
       "        [0., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [0., 1., 1.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 0., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 1., 1.],\n",
       "        [1., 1., 0.],\n",
       "        [1., 1., 0.]]),\n",
       " 'dist': array([[   0., 1749., 1493.,  498.,  498., 2057., 1820., 1859., 1205.,\n",
       "          665.,  791., 1959.,  903., 2089.,  883., 1633.,  598., 1655.,\n",
       "         1298.],\n",
       "        [1749.,    0., 1214., 1649., 1663., 1129.,  336.,  717., 1472.,\n",
       "         1125., 1732., 1010., 1855.,  961., 1216., 1044., 1744.,  440.,\n",
       "         1650.],\n",
       "        [1493., 1214.,    0., 1751., 1762.,  639.,  980., 1846.,  421.,\n",
       "         1285.,  930.,  590.,  974.,  771.,  613.,  244., 1885.,  792.,\n",
       "          531.],\n",
       "        [ 498., 1649., 1751.,    0.,   14., 2227., 1809., 1567., 1553.,\n",
       "          551., 1235., 2113., 1364., 2210., 1156., 1834.,  135., 1685.,\n",
       "         1682.],\n",
       "        [ 498., 1663., 1762.,   14.,    0., 2239., 1822., 1579., 1562.,\n",
       "          564., 1240., 2126., 1368., 2223., 1166., 1846.,  125., 1698.,\n",
       "         1690.],\n",
       "        [2057., 1129.,  639., 2227., 2239.,    0.,  798., 1845., 1058.,\n",
       "         1700., 1567.,  128., 1613.,  222., 1185.,  431., 2356.,  723.,\n",
       "         1142.],\n",
       "        [1820.,  336.,  980., 1809., 1822.,  798.,    0., 1053., 1303.,\n",
       "         1261., 1651.,  682., 1757.,  625., 1139.,  775., 1918.,  204.,\n",
       "         1467.],\n",
       "        [1859.,  717., 1846., 1567., 1579., 1845., 1053.,    0., 2011.,\n",
       "         1201., 2124., 1724., 2264., 1677., 1655., 1716., 1613., 1137.,\n",
       "         2196.],\n",
       "        [1205., 1472.,  421., 1553., 1562., 1058., 1303., 2011.,    0.,\n",
       "         1185.,  530., 1010.,  556., 1189.,  431.,  657., 1686., 1101.,\n",
       "          186.],\n",
       "        [ 665., 1125., 1285.,  551.,  564., 1700., 1261., 1201., 1185.,\n",
       "            0., 1048., 1581., 1195., 1668.,  754., 1329.,  669., 1134.,\n",
       "         1347.],\n",
       "        [ 791., 1732.,  930., 1235., 1240., 1567., 1651., 2124.,  530.,\n",
       "         1048.,    0., 1504.,  146., 1674.,  518., 1145., 1358., 1450.,\n",
       "          551.],\n",
       "        [1959., 1010.,  590., 2113., 2126.,  128.,  682., 1724., 1010.,\n",
       "         1581., 1504.,    0., 1560.,  186., 1096.,  359., 2241.,  597.,\n",
       "         1113.],\n",
       "        [ 903., 1855.,  974., 1364., 1368., 1613., 1757., 2264.,  556.,\n",
       "         1195.,  146., 1560.,    0., 1735.,  639., 1203., 1483., 1554.,\n",
       "          527.],\n",
       "        [2089.,  961.,  771., 2210., 2223.,  222.,  625., 1677., 1189.,\n",
       "         1668., 1674.,  186., 1735.,    0., 1245.,  533., 2334.,  597.,\n",
       "         1297.],\n",
       "        [ 883., 1216.,  613., 1156., 1166., 1185., 1139., 1655.,  431.,\n",
       "          754.,  518., 1096.,  639., 1245.,    0.,  756., 1290.,  941.,\n",
       "          600.],\n",
       "        [1633., 1044.,  244., 1834., 1846.,  431.,  775., 1716.,  657.,\n",
       "         1329., 1145.,  359., 1203.,  533.,  756.,    0., 1966.,  606.,\n",
       "          775.],\n",
       "        [ 598., 1744., 1885.,  135.,  125., 2356., 1918., 1613., 1686.,\n",
       "          669., 1358., 2241., 1483., 2334., 1290., 1966.,    0., 1801.,\n",
       "         1813.],\n",
       "        [1655.,  440.,  792., 1685., 1698.,  723.,  204., 1137., 1101.,\n",
       "         1134., 1450.,  597., 1554.,  597.,  941.,  606., 1801.,    0.,\n",
       "         1268.],\n",
       "        [1298., 1650.,  531., 1682., 1690., 1142., 1467., 2196.,  186.,\n",
       "         1347.,  551., 1113.,  527., 1297.,  600.,  775., 1813., 1268.,\n",
       "            0.]]),\n",
       " 'time_cost': array([[99.        ,  7.99922096,  8.28894721,  2.12098676,  4.20118761,\n",
       "         99.        , 99.        ,  9.04502267,  6.06802982, 99.        ,\n",
       "          7.01771528, 99.        ,  4.73400033,  9.48661967,  7.14830068,\n",
       "         99.        ,  2.14539955,  8.09461011, 99.        ],\n",
       "        [ 6.69412485,  2.077601  , 99.        , 99.        , 99.        ,\n",
       "          5.45750634,  4.69649863,  5.2824806 ,  9.65012768, 99.        ,\n",
       "          4.73401415, 99.        ,  7.65314333,  9.2153458 ,  8.74763526,\n",
       "         99.        ,  5.13494746,  4.34751966, 99.        ],\n",
       "        [ 8.43406687,  4.07947752, 99.        ,  5.50979613, 99.        ,\n",
       "          5.91333886,  3.86480707,  5.82953716, 99.        , 99.        ,\n",
       "         99.        ,  7.04720088, 99.        , 99.        , 99.        ,\n",
       "         99.        ,  5.70253791,  6.25657736,  9.14304113],\n",
       "        [99.        ,  6.00890454,  7.50371318,  5.95677732,  3.29382286,\n",
       "         99.        ,  6.7621179 ,  7.46947322, 99.        ,  3.14746368,\n",
       "          6.81126085, 99.        ,  2.22306105, 99.        ,  7.0214278 ,\n",
       "          2.20589431,  5.41181633, 99.        ,  4.53727066],\n",
       "        [ 7.84136662,  4.22925023,  6.87392962,  8.50923516, 99.        ,\n",
       "          5.34101805,  9.50551858,  8.77266251, 99.        , 99.        ,\n",
       "         99.        , 99.        , 99.        ,  6.14433887,  5.60040344,\n",
       "          6.13706072,  4.81259891, 99.        ,  3.44710538],\n",
       "        [ 8.90414877,  2.85759809, 99.        , 99.        , 99.        ,\n",
       "          8.62967624, 99.        ,  6.62540932,  2.73788008, 99.        ,\n",
       "         99.        ,  6.27760722,  5.0983544 , 99.        ,  9.96959965,\n",
       "          8.67982028,  5.3474655 ,  3.99661711,  8.96189955],\n",
       "        [ 6.82299268,  7.487704  ,  8.73234082,  7.96587262,  8.58388932,\n",
       "          9.98812869, 99.        , 99.        ,  6.80059268, 99.        ,\n",
       "          3.86865429,  6.73564883,  3.39753584,  3.95604143, 99.        ,\n",
       "          5.13506193,  8.71581334,  5.14990705,  8.77863336],\n",
       "        [99.        ,  3.2367241 ,  2.78954385,  5.7650085 , 99.        ,\n",
       "          8.94859459,  9.85230154,  4.8806276 ,  7.93929765,  8.77072831,\n",
       "         99.        ,  6.82729705,  2.65352416,  5.90636121,  6.72072764,\n",
       "          3.36139952,  5.62214547, 99.        , 99.        ],\n",
       "        [ 8.99304575, 99.        , 99.        , 99.        ,  9.26489008,\n",
       "          8.58921596,  9.48816988, 99.        , 99.        ,  7.27461844,\n",
       "         99.        , 99.        , 99.        ,  6.09345364,  8.61982696,\n",
       "          5.3265533 , 99.        , 99.        ,  4.43715118],\n",
       "        [99.        , 99.        ,  4.85287092,  3.76293898,  2.38955311,\n",
       "         99.        ,  6.56210165,  7.70174513,  2.81501918,  5.35064479,\n",
       "         99.        , 99.        ,  2.32422336,  6.90512196,  4.89134327,\n",
       "         99.        , 99.        ,  7.86643559,  4.54952798],\n",
       "        [ 2.87152751, 99.        , 99.        , 99.        ,  3.26486044,\n",
       "          7.51257905, 99.        , 99.        ,  9.22810767,  7.79719883,\n",
       "          3.81021451,  9.80529548, 99.        ,  2.17646114,  3.5982328 ,\n",
       "          7.64657826,  9.48896778,  8.29032917,  5.22698266],\n",
       "        [ 4.58013996,  9.49845662, 99.        , 99.        ,  5.39767581,\n",
       "          5.86464477,  7.82639354,  4.91815806,  8.55377834,  4.28137118,\n",
       "          7.62426561,  7.47568604,  7.75493238,  8.30162125,  9.02505081,\n",
       "          3.22299328,  5.94143317,  8.42643113,  3.86443275],\n",
       "        [99.        ,  8.86392156, 99.        ,  2.75029199, 99.        ,\n",
       "         99.        ,  5.53977589,  9.04313523, 99.        ,  8.45995291,\n",
       "          4.69765835,  6.75542302, 99.        ,  5.14122555,  7.84101321,\n",
       "          3.15536098,  3.67981777, 99.        ,  5.98677901],\n",
       "        [99.        ,  5.62285797,  8.98505139,  6.64090971,  9.76126782,\n",
       "         99.        ,  3.44437007, 99.        , 99.        , 99.        ,\n",
       "          9.34687668, 99.        ,  8.33422074, 99.        , 99.        ,\n",
       "          4.41270802, 99.        ,  2.0288093 ,  7.76288133],\n",
       "        [99.        ,  4.13027013,  9.28367888, 99.        , 99.        ,\n",
       "          3.10546792,  2.56667042, 99.        , 99.        , 99.        ,\n",
       "         99.        ,  4.53183847, 99.        ,  6.64220419,  2.26117025,\n",
       "         99.        ,  7.28840619,  7.52878795, 99.        ],\n",
       "        [99.        ,  7.01964836,  8.83059854,  7.62900647,  4.97798384,\n",
       "          9.90024291,  8.35282458, 99.        ,  9.03714071,  4.5267458 ,\n",
       "          9.59975933,  5.57147053,  7.88402528,  9.80397839,  3.21009903,\n",
       "          6.12289453,  9.39309911,  4.63903476,  6.40810581],\n",
       "        [99.        ,  2.8787457 , 99.        , 99.        ,  9.03977379,\n",
       "          8.73804866, 99.        , 99.        , 99.        ,  6.85422737,\n",
       "          7.13886462,  8.86908867, 99.        ,  4.52288327,  2.03540149,\n",
       "          7.70171366,  9.6244507 ,  3.12248004,  2.26027066],\n",
       "        [ 4.86945478, 99.        , 99.        ,  8.41953131,  3.48963031,\n",
       "          2.65951057,  7.95977061,  3.20967493,  5.34375408,  9.26980434,\n",
       "          3.67861744,  5.10788895,  3.19740895,  7.98998457, 99.        ,\n",
       "          6.45201061,  6.3529542 , 99.        ,  5.5682967 ],\n",
       "        [ 6.81111721, 99.        ,  8.79085721,  2.58909597, 99.        ,\n",
       "          6.33676327, 99.        , 99.        ,  3.59049241, 99.        ,\n",
       "         99.        , 99.        , 99.        ,  9.38861775, 99.        ,\n",
       "         99.        ,  8.21615082,  7.9949055 ,  9.36773956],\n",
       "        [99.        , 99.        , 99.        , 99.        ,  8.23436162,\n",
       "          6.87435811,  8.44598741,  7.47465663,  3.14271645,  9.46714625,\n",
       "          8.17575508,  3.7831035 , 99.        , 99.        , 99.        ,\n",
       "          4.12257638,  3.09774119,  9.53906791,  6.93292848],\n",
       "        [ 4.74504898,  6.18045685,  7.19844078,  5.24663042,  8.84083771,\n",
       "          5.78106953, 99.        ,  8.68076913,  6.09168737, 99.        ,\n",
       "          3.60320742,  5.6558713 ,  3.11184208,  8.76398231,  8.01645437,\n",
       "          6.69170347,  7.5262353 ,  3.09291105,  8.36763718],\n",
       "        [99.        ,  9.99880877, 99.        ,  7.94513923, 99.        ,\n",
       "         99.        ,  2.46050624, 99.        ,  7.51994451,  4.2043341 ,\n",
       "          4.51455569,  9.02817952,  6.62093863,  5.00191868,  8.21395137,\n",
       "          5.16670386,  6.44321234,  9.70790633,  9.12490041],\n",
       "        [ 5.45233013,  4.79874441, 99.        ,  6.62477105, 99.        ,\n",
       "         99.        ,  7.30609191, 99.        ,  7.17017254, 99.        ,\n",
       "         99.        , 99.        , 99.        ,  6.46495003, 99.        ,\n",
       "          2.52603418,  3.64740957, 99.        , 99.        ],\n",
       "        [99.        ,  8.93171696,  7.14016376, 99.        , 99.        ,\n",
       "          5.79636895,  8.14026634,  4.16099844,  9.6260143 ,  3.63658998,\n",
       "          6.02136232, 99.        , 99.        , 99.        ,  6.05464954,\n",
       "         99.        ,  7.47313564,  8.72172174,  9.47694906]]),\n",
       " 'op_cost': array([[999.        ,  48.13017025,  47.12330698,  50.02320425,\n",
       "          45.9519844 , 999.        , 999.        ,  33.83929809,\n",
       "          61.50258682, 999.        ,  22.98776917, 999.        ,\n",
       "          71.78617565,  55.71647405,  51.11303107, 999.        ,\n",
       "          79.80147961,  66.30630808, 999.        ],\n",
       "        [ 72.94759947,  63.7341357 , 999.        , 999.        ,\n",
       "         999.        ,  24.20612147,  41.02485668,  38.31952998,\n",
       "          66.79937289, 999.        ,  34.78001194, 999.        ,\n",
       "          63.39540705,  23.80366359,  82.54311914, 999.        ,\n",
       "          72.97627061,  52.03226643, 999.        ],\n",
       "        [ 57.3266518 ,  30.30526245, 999.        ,  55.81493743,\n",
       "         999.        ,  35.98280328,  88.22232161,  50.12522314,\n",
       "         999.        , 999.        , 999.        ,  71.37944278,\n",
       "         999.        , 999.        , 999.        , 999.        ,\n",
       "          32.3926191 ,  59.10758687,  24.79184666],\n",
       "        [999.        ,  73.16209332,  65.45600569,  28.77129228,\n",
       "          44.4726662 , 999.        ,  60.61619264,  34.73907242,\n",
       "         999.        ,  39.07745571,  66.19991628, 999.        ,\n",
       "          70.57482982, 999.        ,  45.12899972,  32.68810081,\n",
       "          82.54176289, 999.        ,  79.85967437],\n",
       "        [ 28.56515848,  87.74503677,  70.45980271,  20.16506625,\n",
       "         999.        ,  21.89070512,  25.11809446,  86.84697762,\n",
       "         999.        , 999.        , 999.        , 999.        ,\n",
       "         999.        ,  86.42354693,  80.29157961,  20.40685741,\n",
       "          87.08443932, 999.        ,  83.90557328],\n",
       "        [ 85.36734273,  81.89096077, 999.        , 999.        ,\n",
       "         999.        ,  88.90014649, 999.        ,  54.86217095,\n",
       "          72.12830434, 999.        , 999.        ,  28.93942002,\n",
       "          41.40701605, 999.        ,  39.61641433,  30.04774119,\n",
       "          60.19013413,  69.12283739,  78.93019914],\n",
       "        [ 26.89737594,  39.06743856,  25.52771363,  71.45026732,\n",
       "          56.87194034,  50.13159865, 999.        , 999.        ,\n",
       "          60.6258623 , 999.        ,  31.1710981 ,  80.75571751,\n",
       "          35.77146438,  20.84725204, 999.        ,  56.84258654,\n",
       "          71.58788006,  23.2210219 ,  21.86692653],\n",
       "        [999.        ,  89.95432705,  86.82446885,  45.7432277 ,\n",
       "         999.        ,  85.24676831,  70.93259293,  24.70259442,\n",
       "          60.85735695,  55.26207812, 999.        ,  67.25379543,\n",
       "          86.00684248,  79.37913575,  50.94460007,  30.89777364,\n",
       "          85.46615693, 999.        , 999.        ],\n",
       "        [ 77.01415634, 999.        , 999.        , 999.        ,\n",
       "          34.85638671,  84.65615357,  45.7587748 , 999.        ,\n",
       "         999.        ,  48.8120228 , 999.        , 999.        ,\n",
       "         999.        ,  76.08321498,  75.40875463,  22.45259219,\n",
       "         999.        , 999.        ,  65.22672514],\n",
       "        [999.        , 999.        ,  86.72232554,  36.00962708,\n",
       "          39.96574064, 999.        ,  73.96934809,  60.73251026,\n",
       "          58.36022095,  88.12925221, 999.        , 999.        ,\n",
       "          67.43568366,  24.00873047,  59.87223372, 999.        ,\n",
       "         999.        ,  22.70645353,  76.66713477],\n",
       "        [ 82.62871043, 999.        , 999.        , 999.        ,\n",
       "          53.69815803,  42.23648529, 999.        , 999.        ,\n",
       "          82.610674  ,  82.49616157,  22.50328189,  53.92120418,\n",
       "         999.        ,  40.88377323,  25.86883705,  27.55002403,\n",
       "          74.37090121,  71.01574644,  27.64023573],\n",
       "        [ 37.80171811,  20.99567302, 999.        , 999.        ,\n",
       "          83.02524439,  40.91958018,  87.77594084,  26.0966198 ,\n",
       "          49.17916272,  61.48258213,  30.05731082,  60.72812337,\n",
       "          40.76935269,  89.74135059,  87.17743259,  34.6130408 ,\n",
       "          33.97440737,  64.67691631,  27.73724765],\n",
       "        [999.        ,  30.37241554, 999.        ,  46.90087511,\n",
       "         999.        , 999.        ,  32.531486  ,  55.4919108 ,\n",
       "         999.        ,  21.78488084,  54.94101445,  45.46293789,\n",
       "         999.        ,  45.36662281,  58.67006736,  46.43749114,\n",
       "          77.48003529, 999.        ,  35.94952705],\n",
       "        [999.        ,  20.65844421,  35.4620749 ,  48.30335953,\n",
       "          27.35873029, 999.        ,  69.42336197, 999.        ,\n",
       "         999.        , 999.        ,  80.53143784, 999.        ,\n",
       "          61.17071692, 999.        , 999.        ,  35.06505773,\n",
       "         999.        ,  49.70524469,  78.39206659],\n",
       "        [999.        ,  50.08822938,  66.75127135, 999.        ,\n",
       "         999.        ,  21.50366076,  57.11437906, 999.        ,\n",
       "         999.        , 999.        , 999.        ,  84.92538071,\n",
       "         999.        ,  78.75110398,  41.95106762, 999.        ,\n",
       "          57.74559516,  58.59983466, 999.        ],\n",
       "        [999.        ,  56.45136459,  24.04137762,  81.02999416,\n",
       "          26.21701084,  46.549694  ,  62.17844833, 999.        ,\n",
       "          88.46232909,  22.41241313,  51.54882388,  77.11081899,\n",
       "          61.88753661,  44.91572275,  35.97256172,  24.5280077 ,\n",
       "          34.10883526,  45.64979886,  75.07898655],\n",
       "        [999.        ,  20.35942025, 999.        , 999.        ,\n",
       "          24.43606421,  44.71737249, 999.        , 999.        ,\n",
       "         999.        ,  74.07768326,  32.34349544,  44.21756943,\n",
       "         999.        ,  30.99993118,  71.95823613,  70.39562886,\n",
       "          73.4718253 ,  81.4744021 ,  40.67518804],\n",
       "        [ 34.94799996, 999.        , 999.        ,  40.1383559 ,\n",
       "          26.19974849,  41.4878414 ,  89.37515189,  35.20930934,\n",
       "          60.4850258 ,  74.89570232,  31.34233874,  89.10544352,\n",
       "          76.25993544,  67.58893766, 999.        ,  74.53415742,\n",
       "          64.4808366 , 999.        ,  88.66433212],\n",
       "        [ 49.78780238, 999.        ,  75.10991813,  43.59846763,\n",
       "         999.        ,  54.39632593, 999.        , 999.        ,\n",
       "          83.85485414, 999.        , 999.        , 999.        ,\n",
       "         999.        ,  29.30307599, 999.        , 999.        ,\n",
       "          86.94596245,  44.17335904,  55.0601576 ],\n",
       "        [999.        , 999.        , 999.        , 999.        ,\n",
       "          26.14578424,  40.91477064,  81.19255447,  37.53719532,\n",
       "          32.31267998,  64.28330546,  57.93649   ,  31.23297203,\n",
       "         999.        , 999.        , 999.        ,  72.3787323 ,\n",
       "          37.70923386,  71.51458226,  37.24552722],\n",
       "        [ 28.04610652,  24.87620871,  30.72164731,  65.85548446,\n",
       "          66.91045106,  50.99485307, 999.        ,  48.1500035 ,\n",
       "          76.47639387, 999.        ,  69.12525821,  51.95335817,\n",
       "          26.32567438,  52.52741173,  43.25129788,  40.14306088,\n",
       "          22.67050358,  67.86193672,  67.16064671],\n",
       "        [999.        ,  39.70591533, 999.        ,  44.14003892,\n",
       "         999.        , 999.        ,  29.32859331, 999.        ,\n",
       "          85.49109636,  33.74572014,  57.53592902,  54.4673246 ,\n",
       "          70.02162249,  26.90307478,  22.64314761,  24.59443403,\n",
       "          21.7717511 ,  87.22445036,  85.52442252],\n",
       "        [ 59.02115371,  61.37699326, 999.        ,  49.26052049,\n",
       "         999.        , 999.        ,  72.5991945 , 999.        ,\n",
       "          55.476212  , 999.        , 999.        , 999.        ,\n",
       "         999.        ,  65.36496858, 999.        ,  32.35458448,\n",
       "          26.38892908, 999.        , 999.        ],\n",
       "        [999.        ,  75.02394452,  81.27115459, 999.        ,\n",
       "         999.        ,  22.8111646 ,  35.84607755,  50.11204694,\n",
       "          55.66740996,  81.46730853,  52.61480095, 999.        ,\n",
       "         999.        , 999.        ,  60.1215133 , 999.        ,\n",
       "          47.48719265,  42.27787556,  83.67590227]]),\n",
       " 'productivity': array([87.54498276, 92.73764202, 92.68832732, 97.56469308, 91.5342548 ,\n",
       "        87.38064764, 81.88525771, 81.3659248 , 75.49820128, 99.86211627,\n",
       "        83.79428291, 84.43639062, 92.94973953, 70.61174395, 89.53804446,\n",
       "        95.88333273, 97.17376596, 88.13381719, 96.59081763]),\n",
       " 'transportation_cost': array([0.3])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DGList.pop(26)\n",
    "dataset.pop(26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(DGList[:45], dataset[:45])\n",
    "val_dataset = Dataset(DGList[45:], dataset[45:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"../data/GNN_run\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "fh = logging.FileHandler(\"../data/GNN_run.log\")\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]C:\\Users\\ASUS Vivobook\\AppData\\Roaming\\Python\\Python310\\site-packages\\dgl\\backend\\pytorch\\tensor.py:352: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), \"Cannot convert view \" \\\n",
      "  0%|          | 1/5000 [00:02<3:09:19,  2.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 Train:  3743.0914610979335 Val:  7290.065633744426\n",
      "batch_size: 4, n_layers: 1, lr: 0.001, epoch: 0, train_loss: 3743.0914610979335, val_loss: 7290.065633744426\n",
      "\n",
      "../data/model_batch_size:4,n_layers:1,lr:0.001,epoch:0,train_loss:3743.0914610979335,val_loss:7290.065633744426.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 11/5000 [00:24<2:56:34,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  10 Train:  3689.277929382898 Val:  7286.879655723892\n",
      "batch_size: 4, n_layers: 1, lr: 0.001, epoch: 10, train_loss: 3689.277929382898, val_loss: 7286.879655723892\n",
      "\n",
      "../data/model_batch_size:4,n_layers:1,lr:0.001,epoch:10,train_loss:3689.277929382898,val_loss:7286.879655723892.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/5000 [00:46<3:21:15,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  20 Train:  3441.9447285519823 Val:  6557.321866067185\n",
      "batch_size: 4, n_layers: 1, lr: 0.001, epoch: 20, train_loss: 3441.9447285519823, val_loss: 6557.321866067185\n",
      "\n",
      "../data/model_batch_size:4,n_layers:1,lr:0.001,epoch:20,train_loss:3441.9447285519823,val_loss:6557.321866067185.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 25/5000 [00:57<3:10:50,  2.30s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     44\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 45\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     47\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m epoch batch loss is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ASUS Vivobook\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    491\u001b[0m     )\n\u001b[1;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS Vivobook\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS Vivobook\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\function.py:276\u001b[0m, in \u001b[0;36mBackwardCFunction.apply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBackwardCFunction\u001b[39;00m(_C\u001b[38;5;241m.\u001b[39m_FunctionBase, FunctionCtx, _HookMixin):\n\u001b[1;32m--> 276\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m    277\u001b[0m         \u001b[38;5;66;03m# _forward_cls is defined by derived class\u001b[39;00m\n\u001b[0;32m    278\u001b[0m         \u001b[38;5;66;03m# The user should define either backward or vjp but never both.\u001b[39;00m\n\u001b[0;32m    279\u001b[0m         backward_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mbackward  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    280\u001b[0m         vjp_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cls\u001b[38;5;241m.\u001b[39mvjp  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 5000\n",
    "# Списки значений параметров, которые вы хотите протестировать\n",
    "lr_values = [0.001, 0.01, 0.1]\n",
    "n_layers_values = [1, 2, 3]\n",
    "batch_size_values = [4, 8]\n",
    "\n",
    "results_file = open(\"../data/results_objvalues.txt\", \"a\")\n",
    "\n",
    "logger.info('Start training')\n",
    "\n",
    "try:\n",
    "\n",
    "    for lr in lr_values:\n",
    "        for n_layers in n_layers_values:\n",
    "            for batch_size in batch_size_values:\n",
    "                # Создание модели с новыми параметрами\n",
    "                model = GNN(ins_dim=1, ino_dim=20, out_dim=16, n_layers=n_layers)\n",
    "                optim = Adam(model.parameters(), lr=lr)\n",
    "                \n",
    "                train_loader = GraphDataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    drop_last=False,\n",
    "                    shuffle=True\n",
    "                )\n",
    "\n",
    "                val_loader = GraphDataLoader(\n",
    "                    val_dataset,\n",
    "                    batch_size=batch_size,\n",
    "                    drop_last=False,\n",
    "                    shuffle=False\n",
    "                )\n",
    "\n",
    "                # Здесь должен быть код для загрузки данных и создания DataLoader'ов\n",
    "\n",
    "                # Запуск обучения\n",
    "                for epoch in trange(n_epochs):\n",
    "                    train_objvalue = []\n",
    "                    for batch, idx in train_loader:\n",
    "                        logits = model(batch)\n",
    "                        target = batch.edata['target'][os_type]\n",
    "                        loss = F.binary_cross_entropy_with_logits(logits, target)\n",
    "                        batch_loss = loss.item()\n",
    "                        optim.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optim.step()\n",
    "                        logger.info(f\"{epoch} epoch batch loss is {batch_loss}\")\n",
    "\n",
    "                        # Validation\n",
    "\n",
    "                        # Save results to file\n",
    "\n",
    "                        \n",
    "                        for i, graph in enumerate(dgl.unbatch(batch)):\n",
    "                            problem = dataset[idx[i]]\n",
    "                            with graph.local_scope():\n",
    "                                pred_gamma = model.predict(graph, problem)\n",
    "                            train_objvalue.append(\n",
    "                                objvalue(problem, pred_gamma, construct_delta(problem, pred_gamma))\n",
    "                            )\n",
    "\n",
    "                    \n",
    "\n",
    "                    train_loss = sum(train_objvalue)/len(train_objvalue)\n",
    "                    val_loss = validate(model, val_loader, dataset)\n",
    "\n",
    "                    if epoch%10==0:\n",
    "                        #print('Epoch: ', epoch, 'Train: ', train_loss, 'Val: ', val_loss)  \n",
    "                        #print(f\"batch_size: {batch_size}, n_layers: {n_layers}, lr: {lr}, epoch: {epoch}, train_loss: {train_loss}, val_loss: {val_loss}\\n\")\n",
    "                        results_file.write(f\"batch_size: {batch_size}, n_layers: {n_layers}, lr: {lr}, epoch: {epoch}, train_loss: {train_loss}, val_loss: {val_loss}\\n\")\n",
    "                \n",
    "                Path = \"../data/model_\" + f\"batch_size:{batch_size},n_layers:{n_layers},lr:{lr},epoch:{epoch},train_loss:{train_loss},val_loss:{val_loss}.pth\"\n",
    "                torch.save(model.state_dict(), Path)\n",
    "    results_file.close()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    results_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
