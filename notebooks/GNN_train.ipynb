{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133c0767",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"D:/gnn-cloud-manufacturing/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea964685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import Adam\n",
    "from tqdm.auto import trange\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import trange, tqdm\n",
    "from cloudmanufacturing.data import read_fatahi_dataset\n",
    "from cloudmanufacturing.mip_solver import mip_solve\n",
    "from cloudmanufacturing.validation import objvalue, construct_delta\n",
    "from cloudmanufacturing.graph import dglgraph_fixed, graph_gamma, os_type, ss_type, so_type\n",
    "from cloudmanufacturing.graphconv import GNN\n",
    "import dgl\n",
    "from dgl.dataloading import GraphDataLoader\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import pickle\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4662068e",
   "metadata": {},
   "source": [
    "## Загрузка данных и расчет оптимального маршрута"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193189ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_fatahi_dataset('../data/fatahi.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553ac86a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DGList=[]\n",
    "for problem in dataset[:2]:\n",
    "    delta, train_gamma, status, value = mip_solve(problem)\n",
    "    print(status, value)\n",
    "    example_graph = dglgraph_fixed(problem, train_gamma)\n",
    "    example_target = example_graph.edata['target'][os_type]\n",
    "    example_graph.edata['feat'][os_type][:, 0] /= 10\n",
    "    example_graph.edata['feat'][ss_type][:] /= 100\n",
    "    DGList.append(example_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a53111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Запись в файл\n",
    "with open('../data/fatahi_solve.xlsx', 'wb') as f:\n",
    "    pickle.dump(DGList, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ccbb463",
   "metadata": {},
   "source": [
    "## Настройка обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593dc3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GraphDataLoader(\n",
    "    DGList,\n",
    "    batch_size=2,\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833bc0b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "num_batches = len(loader)\n",
    "epoch_train_loss =0\n",
    "batch_size=2\n",
    "train_loss = []\n",
    "train_objvalue = []\n",
    "oper_max = 20\n",
    "model = GNN(ins_dim=1, ino_dim=oper_max, out_dim=16, n_layers=1)\n",
    "optim = Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    for example_graph in tqdm(loader):\n",
    "        logits = model(example_graph)\n",
    "        example_target = example_graph.edata['target'][os_type]\n",
    "        loss = F.binary_cross_entropy_with_logits(logits, example_target)\n",
    "        batch_loss = loss.item()\n",
    "        optim.zero_grad()\n",
    "        batch_loss /= batch_size\n",
    "        print(batch_loss)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "    \n",
    "    train_loss.append(epoch_train_loss / num_batches)\n",
    "    #train_objvalue.append(epoch_train_objvalue / num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef795c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_np = logits.detach().numpy()\n",
    "labels_np = example_target.detach().numpy()\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(labels_np, logits_np)\n",
    "f1_scores = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "# Find the threshold that maximizes the F1-score\n",
    "best_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print(f\"Best threshold based on F1-score: {best_threshold:.2f}\")\n",
    "\n",
    "pr_auc = auc(recall, precision)\n",
    "print(f\"Area under the precision-recall curve: {pr_auc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
